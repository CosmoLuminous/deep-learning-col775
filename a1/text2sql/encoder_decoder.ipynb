{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb54e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 10:13:52.097961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/lib64\n",
      "2023-03-20 10:13:52.141382: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/lib64\n",
      "2023-03-20 10:13:52.141410: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdcba357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae425e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length = 7754\n",
      "Encoder Vocab Size = 2040, Decoder Vocab Size = 2342\n"
     ]
    }
   ],
   "source": [
    "class Text2SQLDataset(Dataset):\n",
    "    def __init__(self, file_path, data_prefix = \"train\"):\n",
    "        self.file_path = file_path\n",
    "        self.data = pd.read_excel(os.path.join(file_path, f\"{data_prefix}_data.xlsx\"))\n",
    "        print(\"Dataset Length =\", len(self.data))\n",
    "        with open(os.path.join(file_path, \"encoder.vocab\"), \"r\") as file:\n",
    "            vocab = file.readlines()\n",
    "        self.encoder_vocab = vocab\n",
    "        \n",
    "        with open(os.path.join(file_path, \"decoder.vocab\"), \"r\") as file:\n",
    "            vocab = file.readlines()\n",
    "        self.decoder_vocab = vocab\n",
    "        \n",
    "        with open(os.path.join(file_path, \"encoder_word2idx.pickle\"), \"rb\") as file:\n",
    "            word2idx = pickle.load(file)\n",
    "        with open(os.path.join(file_path, \"encoder_idx2word.pickle\"), \"rb\") as file:\n",
    "            idx2word = pickle.load(file)\n",
    "            \n",
    "        self.en_word2idx = word2idx\n",
    "        self.en_idx2word = idx2word\n",
    "        \n",
    "        with open(os.path.join(file_path, \"decoder_word2idx.pickle\"), \"rb\") as file:\n",
    "            word2idx = pickle.load(file)\n",
    "        with open(os.path.join(file_path, \"decoder_idx2word.pickle\"), \"rb\") as file:\n",
    "            idx2word = pickle.load(file)\n",
    "            \n",
    "        self.de_word2idx = word2idx\n",
    "        self.de_idx2word = idx2word\n",
    "        print(\"Encoder Vocab Size = {}, Decoder Vocab Size = {}\".format(len(self.en_word2idx), len(self.de_word2idx)))\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx, \"\\n\")\n",
    "        try:\n",
    "            query = [\"<sos>\"]\n",
    "            question = [\"<sos>\"]\n",
    "            query = [\"<sos>\"] + tokenize_query(self.data.loc[idx, \"query\"]) + [\"<eos>\"]\n",
    "            question =  [\"<sos>\"] + tokenize_question(self.data.loc[idx, \"question\"]) + [\"<eos>\"]\n",
    "\n",
    "            query = [self.en_word2idx[q] if q in self.en_word2idx else self.en_word2idx[\"<unk>\"] for q in query]\n",
    "            question = [self.en_word2idx[q] if q in self.en_word2idx else self.en_word2idx[\"<unk>\"] for q in question]\n",
    "\n",
    "            sample = {'question': question, 'query': query}\n",
    "        except:\n",
    "            print(idx)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "def collate(batch):\n",
    "    \n",
    "    max_len_ques = max([len(sample['question']) for sample in batch])\n",
    "    max_len_query = max([len(sample['query']) for sample in batch])\n",
    "    \n",
    "    ques_lens = torch.zeros(len(batch), dtype=torch.long)\n",
    "    padded_ques = torch.zeros((len(batch), max_len_ques), dtype=torch.long)\n",
    "    \n",
    "    query_lens = torch.zeros(len(batch), dtype=torch.long)\n",
    "    padded_query = torch.zeros((len(batch), max_len_query), dtype=torch.long)\n",
    "    \n",
    "    for idx in range(len(batch)):\n",
    "        \n",
    "        query = batch[idx]['query']\n",
    "        question = batch[idx]['question']\n",
    "        \n",
    "        ques_len = len(question)\n",
    "        query_len = len(query)\n",
    "        ques_lens[idx] = ques_len\n",
    "        query_lens[idx] = query_len\n",
    "        \n",
    "        padded_ques[idx, :ques_len] = torch.LongTensor(question)\n",
    "        padded_query[idx, :query_len] = torch.LongTensor(query)\n",
    "        \n",
    "    return {'question': padded_ques, 'query': padded_query, 'ques_lens': query_lens, 'query_lens': query_lens}\n",
    "\n",
    "train_dataset = Text2SQLDataset(\"./processed_data/\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457e9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TOKENS = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\", \"<num_value>\", \"<str_value>\"]\n",
    "SQL_KEYWORDS = [\"t\"+str(i+1) for i in range(10)] + [\".\", \",\", \"(\", \")\", \"in\", \"not\", \"and\", \"between\", \"or\", \"where\",\n",
    "            \"except\", \"union\", \"intersect\",\n",
    "            \"group\", \"by\", \"order\", \"limit\", \"having\",\"asc\", \"desc\",\n",
    "            \"count\", \"sum\", \"avg\", \"max\", \"min\",\n",
    "           \"<\", \">\", \"=\", \"!=\", \">=\", \"<=\",\n",
    "            \"like\",\n",
    "            \"distinct\",\"*\",\n",
    "            \"join\", \"on\", \"as\", \"select\", \"from\"\n",
    "           ] \n",
    "SQL_KEYWORDS = dict(zip(SQL_KEYWORDS, [10]*len(SQL_KEYWORDS)))\n",
    "class GloveEmbeddings():\n",
    "    def __init__(self, embed_dim, word2idx):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.word2idx = word2idx\n",
    "        self.special_tokens = SPECIAL_TOKENS\n",
    "        self.vocab_size = len(word2idx)\n",
    "    \n",
    "    def get_embedding_matrix(self):\n",
    "        # Load pre-trained GloVe embeddings\n",
    "        glove = GloVe(name='6B', dim=self.embed_dim)\n",
    "        embedding_matrix = torch.zeros((self.vocab_size, self.embed_dim))\n",
    "\n",
    "        embedding_matrix[0] = torch.zeros(self.embed_dim)    # Padding token\n",
    "        for i in range(1,len(SPECIAL_TOKENS)):            \n",
    "            embedding_matrix[i] = torch.randn(self.embed_dim)    # Start-of-sentence token\n",
    "            \n",
    "        for k, v in self.word2idx.items():\n",
    "            if k in SPECIAL_TOKENS:\n",
    "                continue\n",
    "            else:            \n",
    "                if k in glove.stoi:\n",
    "                    embedding_matrix[v] = torch.tensor(glove.vectors[glove.stoi[k]])\n",
    "                else:\n",
    "                    embedding_matrix[v] = embedding_matrix[1]\n",
    "#                     print(\"unknown token\", v)\n",
    "\n",
    "        return embedding_matrix\n",
    "\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, hidden_units=1024, num_layers=1, p = 0.5, bidirectional=False, embed_matrix=None):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embed_matrix = None\n",
    "        if self.embed_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, padding_idx=0)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, self.embed_dim, padding_idx=0)\n",
    "        self.LSTM = nn.LSTM(embed_dim, hidden_units, num_layers = num_layers, dropout=p, batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(\"ENCODER INPUT SHAPE\", x.shape)\n",
    "        x = self.dropout(self.embedding(x))\n",
    "#         print(\"ENCODER EMBEDDING SHAPE\", x.shape)\n",
    "        \n",
    "        encoder_out, (ht, ct) = self.LSTM(x)        \n",
    "#         print(\"ENCODER OUTPUT SHAPE: encoder_out, ht, ct\", encoder_out.shape, ht.shape, ct.shape)\n",
    "        \n",
    "        return encoder_out, (ht, ct)\n",
    "    \n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, hidden_units=1024, num_layers=1, p = 0.5):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(input_size, self.embed_dim, padding_idx=0)\n",
    "        self.LSTM = nn.LSTM(embed_dim, hidden_units, num_layers = num_layers, dropout=p, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_units, input_size)\n",
    "        \n",
    "    def forward(self, x, h0_c0):\n",
    "#         print(\"|== Decoder Input Shape: x, h0_c0\", x.shape, len(h0_c0), h0_c0[0].shape, h0_c0[1].shape)\n",
    "        x = self.dropout(self.embedding(x))\n",
    "#         print(\"|== Decoder Embeddings Shape: x\", x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "#         print(\"|== Decoder Embeddings unsqueezed(0) Shape: x\", x.shape)\n",
    "        decoder_out, (ht, ct) = self.LSTM(x, h0_c0)\n",
    "#         print(\"|== Decoder Output Shape Shape: decoder_out, ht, ct\", decoder_out.shape, ht.shape, ct.shape)\n",
    "        \n",
    "        out = self.fc(decoder_out)\n",
    "#         print(\"|== Decoder FC OUT Shape: out\", out.shape)\n",
    "        \n",
    "        return out, (ht, ct)\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.args = args\n",
    "        self.model_type = args.model_type\n",
    "        self.embed_dim = args.embed_dim        \n",
    "        self.encoder_hidden_units = args.en_hidden\n",
    "        self.decoder_hidden_units = args.de_hidden\n",
    "        self.encoder_num_layers = args.en_num_layers\n",
    "        self.decoder_num_layers = args.de_num_layers\n",
    "        self.processed_data = args.processed_data\n",
    "        self.encoder_word2idx = self.get_encoder_word2idx()\n",
    "        self.decoder_word2idx = self.get_decoder_word2idx()\n",
    "        self.encoder_input_size = len(self.encoder_word2idx)\n",
    "        self.decoder_input_size = len(self.decoder_word2idx)\n",
    "        self.encoder = self.get_encoder()\n",
    "        self.decoder = self.get_decoder()\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_encoder_word2idx(self):\n",
    "        with open(os.path.join(self.processed_data, \"encoder_word2idx.pickle\"), \"rb\") as file:\n",
    "            word2idx = pickle.load(file)\n",
    "        with open(os.path.join(self.processed_data, \"encoder_idx2word.pickle\"), \"rb\") as file:\n",
    "            idx2word = pickle.load(file)\n",
    "            \n",
    "#         self.en_word2idx = word2idx\n",
    "#         self.en_idx2word = idx2word        \n",
    "        \n",
    "        return word2idx\n",
    "    \n",
    "    def get_decoder_word2idx(self):\n",
    "        \n",
    "        with open(os.path.join(self.processed_data, \"decoder_word2idx.pickle\"), \"rb\") as file:\n",
    "            word2idx = pickle.load(file)\n",
    "        with open(os.path.join(self.processed_data, \"decoder_idx2word.pickle\"), \"rb\") as file:\n",
    "            idx2word = pickle.load(file)\n",
    "            \n",
    "#         self.de_word2idx = word2idx\n",
    "#         self.de_idx2word = idx2word\n",
    "        \n",
    "        return word2idx\n",
    "    \n",
    "    def get_encoder(self):\n",
    "        print(\"Loading GloVe embeddings...\")\n",
    "        glove = GloveEmbeddings(self.embed_dim, self.encoder_word2idx)\n",
    "        embedding_matrix = glove.get_embedding_matrix()\n",
    "        print(\"Loading Encoder...\")\n",
    "        encoder = LSTMEncoder(input_size = self.encoder_input_size, embed_dim = self.embed_dim, \n",
    "                              hidden_units=self.encoder_hidden_units, num_layers=self.encoder_num_layers, p = 0.3, bidirectional=False, embed_matrix=embedding_matrix)\n",
    "        \n",
    "        return encoder\n",
    "    \n",
    "    def get_decoder(self):\n",
    "        \n",
    "        if self.model_type == \"Seq2Seq\":\n",
    "            print(\"Loading Seq2Seq LSTM Decoder...\")\n",
    "            decoder = LSTMDecoder(input_size = self.decoder_input_size, embed_dim = self.embed_dim, \n",
    "                              hidden_units=self.decoder_hidden_units, num_layers=self.decoder_num_layers, p = 0.3)\n",
    "        \n",
    "        elif self.model_type == \"Seq2SeqAttn\":\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "        return decoder\n",
    "        \n",
    "    def forward(self, question, query, tf_ratio=0.5):\n",
    "        batch_size = question.shape[0]\n",
    "        target_len = query.shape[1]\n",
    "        \n",
    "        _, (hidden, cell) = self.encoder(question)\n",
    "        \n",
    "        target_vocab_size = self.decoder_input_size\n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
    "        \n",
    "        x = query[:,0]\n",
    "        for t in range(1, target_len):\n",
    "            output, (hidden, cell) = self.decoder(x, (hidden, cell))\n",
    "#             print(\"Seq2seq out shape\", output.shape)\n",
    "            output = output.squeeze(1)\n",
    "            outputs[:,t,:] = output\n",
    "            x = output.argmax(dim=1)\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = Seq2Seq(args).to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "schedulers = [\n",
    "        optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1, last_epoch=- 1, verbose=False),\n",
    "        optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs, verbose=False)\n",
    "        ]\n",
    "scheduler =  schedulers[1]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle=True, \n",
    "                          num_workers=args.num_workers, collate_fn=collate)\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for i, data in enumerate(train_loader):\n",
    "    #     print(data['question'].shape, data['query'].shape, data['ques_lens'].shape, data['query_lens'].shape)\n",
    "        optimizer.zero_grad()\n",
    "        question = data['question'].to(device)\n",
    "        query = data['query'].to(device)\n",
    "        output = model(question, query)\n",
    "    #     print(\"output and target\", output.shape, query.shape)\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        query = query.reshape(-1)    \n",
    "    #     print(\"reshaped output and target\", output.shape, query.shape)\n",
    "        loss = criterion(output, query)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "    scheduler.step()\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2a3bef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 20 10:11:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 5000     Off  | 00000000:C1:00.0 Off |                  Off |\n",
      "| 33%   29C    P8    16W / 230W |   1375MiB / 16125MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     36653      C   ...0/anaconda3/bin/python3.7     1259MiB |\n",
      "|    0   N/A  N/A     41115      C   ...ffice/program/soffice.bin      113MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355e8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    def __init__(self):\n",
    "        self.model_type = \"Seq2Seq\"\n",
    "        self.data_dir = \"./data\"\n",
    "        self.batch_size = 16\n",
    "        self.num_workers = 8\n",
    "        self.epochs = 100\n",
    "        self.en_hidden = 512\n",
    "        self.de_hidden = 512\n",
    "        self.en_num_layers = 1\n",
    "        self.de_num_layers = 1\n",
    "        self.embed_dim = 300\n",
    "        self.processed_data = \"./processed_data/\"\n",
    "        \n",
    "args = ARGS()\n",
    "\n",
    "def get_parser():\n",
    "    \"\"\"\n",
    "    Generate a parameter parser\n",
    "    \"\"\"\n",
    "    # parse parameters\n",
    "    parser = argparse.ArgumentParser(description=\"Text2SQL\")\n",
    "    \n",
    "    # model type\n",
    "    parser.add_argument(\"--model_type\", type=str, default=\"Seq2Seq\", help=\"Select the model you want to run from [Seq2Seq, Seq2SeqAttn].\")\n",
    "\n",
    "    # path to data files.\n",
    "    parser.add_argument(\"--data_dir\", type=str, default=\"./data\", help=\"Path to dataset directory.\")\n",
    "\n",
    "    # path to result files.\n",
    "    parser.add_argument(\"--result_dir\", type=str, default=\"./results\", help=\"Path to dataset directory.\")\n",
    "\n",
    "    # path to model checkpoints.\n",
    "    parser.add_argument(\"--checkpoint_dir\", type=str, default=\"./checkpoints\", help=\"Path to model checkpoints.\")\n",
    "    \n",
    "    # path to model checkpoints.\n",
    "    parser.add_argument(\"--processed_data\", type=str, default=\"./processed_data\", help=\"Path to processed data.\")\n",
    "\n",
    "    # batch size training\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16, help=\"Batch size to be used during training.\")\n",
    "\n",
    "    # number of workers for dataloader\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=8, help=\"Number of workers used for dataloading.\")\n",
    "\n",
    "    # max number of epochs\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100, help=\"Number of workers used for dataloading.\")\n",
    "\n",
    "    parser.add_argument(\"--en_hidden\", type=int, default=512, help=\"Encoder Hidden Units\")\n",
    "    \n",
    "    parser.add_argument(\"--de_hidden\", type=int, default=512, help=\"Decoder Hidden Units\")\n",
    "\n",
    "    parser.add_argument(\"--en_num_layers\", type=int, default=1, help=\"Number of lstm layers in encoder.\")\n",
    "    \n",
    "    parser.add_argument(\"--de_num_layers\", type=int, default=1, help=\"Number of lstm layers in decoder.\")    \n",
    "    \n",
    "    parser.add_argument(\"--embed_dim\", type=int, default=300, help=\"Embeddings dimension for both encoder and decoder.\")\n",
    "\n",
    "    return parser\n",
    "# parser = get_parser()\n",
    "# args = parser.parse_args()\n",
    "# args.data_dir = os.path.relpath(args.data_dir)\n",
    "# print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde0c7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>question</th>\n",
       "      <th>query</th>\n",
       "      <th>orig_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>music_1</td>\n",
       "      <td>what is the most popular file format ?</td>\n",
       "      <td>select formats from files group by formats ord...</td>\n",
       "      <td>select formats from files group by formats ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scholar</td>\n",
       "      <td>who is the most published author in syntactic ...</td>\n",
       "      <td>select distinct count ( t4 . paperid ) , t3 . ...</td>\n",
       "      <td>select distinct count ( t4.paperid )  ,  t3.au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight_4</td>\n",
       "      <td>find the name of airline which runs the most n...</td>\n",
       "      <td>select t1 . name from airlines as t1 join rout...</td>\n",
       "      <td>select t1.name from airlines as t1 join routes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cre_Docs_and_Epenses</td>\n",
       "      <td>how many documents have expenses ?</td>\n",
       "      <td>select count ( * ) from documents_with_expenses</td>\n",
       "      <td>select count(*) from documents_with_expenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine_repair</td>\n",
       "      <td>list the names of technicians in ascending ord...</td>\n",
       "      <td>select name from technician order by age asc</td>\n",
       "      <td>select name from technician order by age asc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  db_id                                           question  \\\n",
       "0               music_1             what is the most popular file format ?   \n",
       "1               scholar  who is the most published author in syntactic ...   \n",
       "2              flight_4  find the name of airline which runs the most n...   \n",
       "3  cre_Docs_and_Epenses                 how many documents have expenses ?   \n",
       "4        machine_repair  list the names of technicians in ascending ord...   \n",
       "\n",
       "                                               query  \\\n",
       "0  select formats from files group by formats ord...   \n",
       "1  select distinct count ( t4 . paperid ) , t3 . ...   \n",
       "2  select t1 . name from airlines as t1 join rout...   \n",
       "3    select count ( * ) from documents_with_expenses   \n",
       "4       select name from technician order by age asc   \n",
       "\n",
       "                                          orig_query  \n",
       "0  select formats from files group by formats ord...  \n",
       "1  select distinct count ( t4.paperid )  ,  t3.au...  \n",
       "2  select t1.name from airlines as t1 join routes...  \n",
       "3       select count(*) from documents_with_expenses  \n",
       "4       select name from technician order by age asc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel(\"./processed_data/val_data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637c9fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    cre_Docs_and_Epenses\n",
       "1                 scholar\n",
       "4          machine_repair\n",
       "Name: db_id, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[np.array([3,1,4]), 'db_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a116df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.array([3,1,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f12a1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('all', '1939', '0.000', '0.000')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./results/seq2seq/train_eval_results.txt\", \"r\") as file:\n",
    "    data = file.readlines()\n",
    "    \n",
    "data[0].split()[-1], data[1].split()[-1], data[3].split()[-1], data[6].split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d795c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8804, -0.6410, -1.2031,  1.0786,  0.7089]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(1, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85230079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.8804, 1.0786, 0.7089]]), tensor([[0, 3, 4]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v, i = a.topk(3, dim=1)\n",
    "v, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b57bb964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "for j, ind in enumerate(i):\n",
    "    print(j, ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545acec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
